{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-820b39bc0fb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\anaconda navigator\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda navigator\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda navigator\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda navigator\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda navigator\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find if there are any null values in given dataset\n",
    "for i in df.select_dtypes(exclude='object'):\n",
    "    if(df[i].isnull().sum()>0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=None\n",
    "df.drop('customerID',axis=1,inplace=True) # Dropping customerID, as it wont be of much use to use\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include='object').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This copy is only for visualization of data before encoding!\n",
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultipleLines,InternetService,OnlineSecurity,OnlineBackup,DeviceProtection,TechSupport,\n",
    "# StreamingTV,StreamingMovies,Contract [multiclass features]\n",
    "\n",
    "df['gender']=df['gender'].replace({'Male':1,'Female':0})\n",
    "df['Partner']=df['Partner'].replace({'Yes':1,'No':0})\n",
    "df['Dependents']=df['Dependents'].replace({'Yes':1,'No':0})\n",
    "df['PhoneService']=df['PhoneService'].replace({'Yes':1,'No':0})\n",
    "df['PaperlessBilling']=df['PaperlessBilling'].replace({'Yes':1,'No':0})\n",
    "df['Churn']=df['Churn'].replace({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Problems ####################################\n",
    "#   1-We have to convert all categorical variables by using manual label encoding.\n",
    "#   2-fix the datatype of TotalCharges which is numerical feature but it appears to be object datatype.\n",
    "#   3- Replace null values by respective mean/median.\n",
    "\n",
    "# for i in df.select_dtypes(include='object'):\n",
    "#     if df[i].nunique()>2:\n",
    "#         print(i,':\\n',df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing data type of totalcharges to float and Imputing missing values with median.\n",
    "df['TotalCharges']=pd.to_numeric(df['TotalCharges'],errors='coerce')\n",
    "df['TotalCharges']=df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "\n",
    "##### using get_dummies to encode multiclass features\n",
    "dfcopy=pd.get_dummies(df.select_dtypes(include='object'),drop_first=True) #creating dummies with 3 categories.\n",
    "df=pd.concat([df,dfcopy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "       'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "       'Contract', 'PaymentMethod'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is clean dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visulization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df1.select_dtypes(include='object'):\n",
    "    sns.countplot(df1[i])\n",
    "    plt.show()\n",
    "# plt.figure(figsize=(15,18))\n",
    "# for i in range(1, len(df1.select_dtypes(include=object).columns)-1):\n",
    "#     plt.subplot(10, 2, i)\n",
    "#     sns.countplot(df1[df1.columns[i]])\n",
    "# plt.show()\n",
    "\n",
    "## As we can observe from given data,\n",
    "## 1-There are equal number of males and females,equal number of people with and without partner in the given data.\n",
    "## 2-There are around roughly 2000 people who are dependents\n",
    "## 3-Almost 90% of people do have access to phone service.But,there are a few people who dont have access to phone service.\n",
    "## 4-There are people who have access to landline internet n/w as well mobile n/w\n",
    "## 5-People with Fiber optic,DSL access are more.\n",
    "## 6-Its very surprising that majority of people from the sample dont have online security.\n",
    "## 7-Again majority of people also dont onlinebackup\n",
    "## 8-But,Its good to see that people care enough about their devices so as to protect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tenure to years!\n",
    "df1['tenure']=np.round((df1['tenure']/12),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['TotalCharges']=pd.to_numeric(df1['TotalCharges'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(1,3,figsize=(15,5))\n",
    "sns.distplot(df1['tenure'],ax=axes[0])\n",
    "sns.distplot(df1['MonthlyCharges'],ax=axes[1])\n",
    "sns.distplot(df1['TotalCharges'],ax=axes[2])\n",
    "plt.show()\n",
    "#So,majority of people stick around with their operator from 0 to 6 years.\n",
    "#Monthly charges range around from 20 to 120 dollars.\n",
    "#Total charges incurred by customers are around 0 to 8000 dollars per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df1['MonthlyCharges'],df1['TotalCharges'],hue=df1['Churn'])\n",
    "plt.show()\n",
    "# People who are churning to other operator seem mostly below 4000 only.There are a few people with monthly charges\n",
    "# and with total charges above 5000,But,the frequency to churn is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Churn']=df1['Churn'].replace({'Yes':1,'No':0})\n",
    "df1['Churn']=df1['Churn'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df1.corr(),annot=True)\n",
    "# Total charges,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder,OneHotEncoder #this is optional\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold,GridSearchCV,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression,Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score,roc_auc_score,classification_report,mean_squared_error,accuracy_score,confusion_matrix\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Logistic and Naive Bayes Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']\n",
    "\n",
    "lr = LogisticRegression()\n",
    "gb = GaussianNB()\n",
    "models = []\n",
    "models.append(('LogisticRegression',lr))\n",
    "models.append(('NaviveBayes',gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(shuffle=True, n_splits=5, random_state=0)\n",
    "    cv_results = cross_val_score(model, X, y, cv=kfold, scoring='roc_auc')\n",
    "    results.append(1 - cv_results)\n",
    "    names.append(name)\n",
    "    print('%s : %f(%f)' %(name,np.mean(cv_results), np.var(cv_results,ddof=1)))\n",
    "# boxplot algorithm comparision\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting X&y using train_test:\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=8)\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "y_prob_train = logreg.predict_proba(X_train)\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "y_prob_test = logreg.predict_proba(X_test)\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\n",
    "print('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "print('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\n",
    "print('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n",
    "      \n",
    "from sklearn.metrics import log_loss\n",
    "print('log loss: ',log_loss(y_test,y_prob_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_params = {'n_neighbors':np.arange(3,20), 'weights':['uniform','distance']}\n",
    "gscv = GridSearchCV(knn, knn_params, cv=5, scoring='roc_auc')\n",
    "gscv.fit(X_scaled, y)\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_best_knn=gscv.best_params_\n",
    "\n",
    "KNN=KNeighborsClassifier(**gscv_best_knn)\n",
    "\n",
    "KNN.fit(X_scaled,y)\n",
    "KNN.score(X_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting X&y using train_test:\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=.2,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_train = KNN.predict_proba(X_train)\n",
    "y_pred_train = KNN.predict(X_train)\n",
    "y_prob_test = KNN.predict_proba(X_test)\n",
    "y_pred_test = KNN.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\n",
    "print('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "print('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\n",
    "print('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n",
    "      \n",
    "from sklearn.metrics import log_loss\n",
    "print('log loss: ',log_loss(y_test,y_prob_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Decision tree: [No need to do scaling now]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt_params = {'max_depth':np.arange(1,10), 'min_samples_leaf':np.arange(2,100), 'criterion':['entropy','gini']}\n",
    "gscv = GridSearchCV(dt, dt_params, cv=5, scoring='roc_auc')\n",
    "gscv.fit(X, y)\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_best_DT=gscv.best_params_\n",
    "DT=DecisionTreeClassifier(**gscv_best_DT)\n",
    "DT.fit(X,y)\n",
    "DT.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting X&y using train_test:\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=.2,random_state=8)\n",
    "\n",
    "\n",
    "DT.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_train = DT.predict_proba(X_train)\n",
    "y_pred_train = DT.predict(X_train)\n",
    "y_prob_test = DT.predict_proba(X_test)\n",
    "y_pred_test = DT.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\n",
    "print('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "print('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\n",
    "print('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n",
    "      \n",
    "from sklearn.metrics import log_loss\n",
    "print('log loss: ',log_loss(y_test,y_prob_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_avg = []\n",
    "auc_var = []\n",
    "for ne in np.arange(1,30):\n",
    "    RF=RandomForestClassifier(n_estimators=ne,random_state=0)\n",
    "    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n",
    "    auc = cross_val_score(RF, X, y, cv=kfold, scoring='roc_auc')\n",
    "    auc_avg.append(1 - np.mean(auc))\n",
    "    auc_var.append(np.var(auc,ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\n",
    "print('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting X&y using train_test:\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=.2,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF=RandomForestClassifier(n_estimators=16)\n",
    "RF.fit(X,y)\n",
    "RF.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_train = RF.predict_proba(X_train)\n",
    "y_pred_train = RF.predict(X_train)\n",
    "y_prob_test = RF.predict_proba(X_test)\n",
    "y_pred_test = RF.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\n",
    "print('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "print('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\n",
    "print('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n",
    "      \n",
    "from sklearn.metrics import log_loss\n",
    "print('log loss: ',log_loss(y_test,y_prob_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison so far..!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "gb = GaussianNB()\n",
    "knn=KNeighborsClassifier(**gscv_best_knn)\n",
    "dt = DecisionTreeClassifier(**gscv_best_DT)\n",
    "rf=RandomForestClassifier(n_estimators=17,random_state=0)\n",
    "models = []\n",
    "models.append(('LogisticRegression',lr))\n",
    "models.append(('NaiveBayes',gb))\n",
    "models.append(('KNeighborsClassifier',knn))\n",
    "models.append(('DecisionTreeClassifier',dt))\n",
    "models.append(('RandomForestClassifier',rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(shuffle=True, n_splits=5, random_state=0)\n",
    "    cv_results = cross_val_score(model, X_scaled, y, cv=kfold, scoring='roc_auc')\n",
    "    results.append(1-cv_results)\n",
    "    names.append(name)\n",
    "    print('%s : %f(%f)' %(name,1 - np.mean(cv_results), np.var(cv_results,ddof=1)))\n",
    "# boxplot algorithm comparision\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "fig.suptitle('Algorithm Comparision')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So, As we can observe from above box plot,bias variance tradeoff for logistic regression is better as\n",
    "comapared to other other classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- RF Boosting Classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']\n",
    "\n",
    "auc_avg = []\n",
    "auc_var = []\n",
    "for ne in np.arange(1,20):\n",
    "    ab_rf = AdaBoostClassifier(base_estimator=rf,n_estimators= ne,random_state=0)\n",
    "    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n",
    "    auc = cross_val_score(ab_rf, X, y, cv=kfold, scoring='roc_auc')\n",
    "    auc_avg.append(1 - np.mean(auc))\n",
    "    auc_var.append(np.var(auc,ddof=1))\n",
    "\n",
    "print('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\n",
    "print('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From ada boosting the random forest,we can observe that,bias reduced slightly and variance was already reduced\n",
    "# because of random forest itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Ada boosted DT: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']\n",
    "\n",
    "auc_avg = []\n",
    "auc_var = []\n",
    "for ne in np.arange(1,30):\n",
    "    ab_dt = AdaBoostClassifier(n_estimators= ne,random_state=0)\n",
    "    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n",
    "    auc = cross_val_score(ab_dt, X, y, cv=kfold, scoring='roc_auc')\n",
    "    auc_avg.append(1 - np.mean(auc))\n",
    "    auc_var.append(np.var(auc,ddof=1))\n",
    "\n",
    "print('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\n",
    "print('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again,here as well,bias error of decision tree was reduced slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Ada boosted NB:[Needs scaled X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']\n",
    "auc_avg = []\n",
    "auc_var = []\n",
    "for ne in np.arange(1,30):\n",
    "    ab_nb = AdaBoostClassifier(base_estimator=gb,n_estimators=ne, random_state=0)\n",
    "    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n",
    "    auc = cross_val_score(ab_nb, X_scaled, y, cv=kfold, scoring='roc_auc')\n",
    "    auc_avg.append(1 - np.mean(auc))\n",
    "    auc_var.append(np.var(auc,ddof=1))\n",
    "print('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\n",
    "print('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 - Ada boosted Logistic Regression:[scaled X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']\n",
    "auc_avg = []\n",
    "auc_var = []\n",
    "for ne in np.arange(1,30):\n",
    "    ab_lr = AdaBoostClassifier(base_estimator=lr,n_estimators=ne, random_state=0)\n",
    "    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n",
    "    auc = cross_val_score(ab_lr, X_scaled, y, cv=kfold, scoring='roc_auc')\n",
    "    auc_avg.append(1 - np.mean(auc))\n",
    "    auc_var.append(np.var(auc,ddof=1))\n",
    "print('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\n",
    "print('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Bagged Logistic Regression:[scaled X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']\n",
    "auc_avg = []\n",
    "auc_var = []\n",
    "for ne in np.arange(1,30):\n",
    "    bgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0, n_estimators=ne)\n",
    "    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n",
    "    auc = cross_val_score(bgcl_lr, X_scaled, y, cv=kfold, scoring='roc_auc')\n",
    "    auc_avg.append(1 - np.mean(auc))\n",
    "    auc_var.append(np.var(auc,ddof=1))\n",
    "print('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\n",
    "print('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "gb = GaussianNB()\n",
    "knn=KNeighborsClassifier(**gscv_best_knn)\n",
    "dt = DecisionTreeClassifier(**gscv_best_DT)\n",
    "rf=RandomForestClassifier(n_estimators=17,random_state=0)\n",
    "\n",
    "ab_rf = AdaBoostClassifier(base_estimator=rf,n_estimators=2,random_state=0)\n",
    "ab_dt = AdaBoostClassifier(base_estimator=dt,n_estimators=21,random_state=0)\n",
    "ab_nb=  AdaBoostClassifier(base_estimator=gb,n_estimators=3,random_state=0)\n",
    "ab_lr=  AdaBoostClassifier(base_estimator=lr,n_estimators=29,random_state=0)\n",
    "bgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0, n_estimators=17)\n",
    "\n",
    "\n",
    "#gbcl = GradientBoostingClassifier(random_state=0, n_estimators=27)\n",
    "#stacked = VotingClassifier(estimators=[('BoostedDT',ab_dt),('BaggedLR',bgcl_lr)], voting='soft')\n",
    "models = []\n",
    "models.append(('LogisticRegression',lr))\n",
    "models.append(('NaiveBayes',gb))\n",
    "models.append(('KNeighborsClassifier',knn))\n",
    "models.append(('DecisionTreeClassifier   ',dt))\n",
    "models.append(('RandomForestClassifier',rf))\n",
    "models.append(('BoostedRF',ab_rf))\n",
    "models.append(('BoostedDT',ab_dt))\n",
    "models.append(('BoostedNB',ab_nb))\n",
    "models.append(('BoostedLR',ab_lr))\n",
    "models.append(('BaggedLR',bgcl_lr))\n",
    "\n",
    "#models.append(('GBoostClassifier',gbcl))\n",
    "#models.append(('VotingClassifier',stacked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(shuffle=True, n_splits=5, random_state=0)\n",
    "    cv_results = cross_val_score(model, X_scaled, y, cv=kfold, scoring='roc_auc')\n",
    "    results.append(1 - cv_results)\n",
    "    names.append(name)\n",
    "    print('%s : %f(%f)' %(name,1 - np.mean(cv_results), np.var(cv_results,ddof=1)))\n",
    "# boxplot algorithm comparision\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "fig.suptitle('Algorithm Comparision')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model with testing:\n",
    "# We choose Logistic Regresion as our model because it is best in terms of bias and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_prob = logreg.predict_proba(X_test)\n",
    "print(y_prob[:,1]) \n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(y_pred)\n",
    "      \n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "## For test data \n",
    "\n",
    "y_prob_train = logreg.predict_proba(X_train) # probability prediction of train\n",
    "y_pred_train = logreg.predict(X_train) # actual prediction of train \n",
    "y_prob_test = logreg.predict_proba(X_test) # probability prediction of test\n",
    "y_pred_test = logreg.predict(X_test) # actual prediction of test\n",
    "\n",
    "print('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\n",
    "print('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "print('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\n",
    "print('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n",
    "      \n",
    "from sklearn.metrics import log_loss\n",
    "print('log loss: ',log_loss(y_test,y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for same results everytime\n",
    "seed=0\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "\n",
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state =3)\n",
    "\n",
    "#declare the models\n",
    "lr = LogisticRegression()\n",
    "rf=RandomForestClassifier(n_estimators=17,random_state=0)\n",
    "adb=ensemble.AdaBoostClassifier()\n",
    "bgc=ensemble.BaggingClassifier()\n",
    "gnb = GaussianNB()\n",
    "knn=KNeighborsClassifier(**gscv_best_knn)\n",
    "dt = DecisionTreeClassifier(**gscv_best_DT)\n",
    "ab_rf = AdaBoostClassifier(base_estimator=rf,n_estimators=2,random_state=0)\n",
    "ab_dt = AdaBoostClassifier(base_estimator=dt,n_estimators=21,random_state=0)\n",
    "ab_nb=  AdaBoostClassifier(base_estimator=gnb,random_state=0)\n",
    "ab_lr=  AdaBoostClassifier(base_estimator=lr,n_estimators=29,random_state=0)\n",
    "bgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0, n_estimators=17)\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "models=[lr,rf,adb,bgc,gnb,knn,dt,ab_rf,ab_dt,ab_nb,ab_lr,bgcl_lr,xgb]\n",
    "sctr,scte,auc,ps,rs=[],[],[],[],[]\n",
    "def ens(X_train,X_test, y_train, y_test):\n",
    "    for model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            train_score=model.score(X_train,y_train)\n",
    "            test_score=model.score(X_test,y_test)\n",
    "            ac=metrics.roc_auc_score(y_test,y_test_pred)\n",
    "            p_score=metrics.precision_score(y_test,y_pred)\n",
    "            r_score=metrics.recall_score(y_test,y_pred)\n",
    "            sctr.append(train_score)\n",
    "            scte.append(test_score)\n",
    "            ps.append(p_score)\n",
    "            rs.append(r_score)\n",
    "            auc.append(ac)\n",
    "    return sctr,scte,auc,ps,rs\n",
    "ens(X_train,X_test, y_train, y_test)\n",
    "\n",
    "ensemble=pd.DataFrame({'names':['Logistic Regression','Random Forest','Ada boost','Bagging',\n",
    "                                'Naive-Bayes','KNN','Decistion Tree','ab_rf','ab_dt','ab_nb','ab_lr','bgcl_lr','XGB'],\n",
    "                       'auc_score':auc,'training':sctr,'testing':scte,'precision':ps,'recall':rs})\n",
    "ensemble=ensemble.sort_values(by=['testing','auc_score'],ascending=False).reset_index(drop=True)\n",
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# model = XGBClassifier()\n",
    "# model.fit(X_train, y_train)\n",
    "# preds = model.predict(X_test)\n",
    "# metrics.roc_auc_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
